import os
import json
import time
import base64
from datetime import datetime
from pathlib import Path

import pandas as pd
import streamlit as st
from PIL import Image
from dotenv import load_dotenv, find_dotenv

from langchain_core.messages import HumanMessage
from langchain_openai import ChatOpenAI

# ===========================
# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã
# ===========================
load_dotenv(find_dotenv())

st.set_page_config(page_title="–¢–µ—Å—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è", page_icon="üß™", layout="wide")
st.title("üß™ –¢–µ—Å—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")

# ===========================
# –•–µ–ª–ø–µ—Ä—ã
# ===========================
def load_df_from_state_or_file() -> pd.DataFrame:
    df = st.session_state.get("df")
    if df is not None and not df.empty:
        return df
    # fallback
    return pd.read_csv("data.csv")

def validate_df(df: pd.DataFrame):
    required = ["image_name", "question", "answer"]
    missing = [c for c in required if c not in df.columns]
    if missing:
        st.error(f"–í CSV –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã: {', '.join(missing)}")
        st.stop()

@st.cache_data(show_spinner=False)
def encode_image(image_path: Path) -> str:
    with open(image_path, "rb") as f:
        return base64.b64encode(f.read()).decode("utf-8")

def image_mime(path: Path) -> str:
    suf = path.suffix.lower().lstrip(".")
    return f"image/{'jpeg' if suf in ['jpg', 'jpeg'] else suf}"

def get_llm(api_key: str, model_name: str, temperature: float = 0.0, max_tokens: int = 2048) -> ChatOpenAI:
    return ChatOpenAI(
        openai_api_key=api_key,
        openai_api_base="https://openrouter.ai/api/v1",
        model_name=model_name,
        max_tokens=max_tokens,
        temperature=temperature,
        default_headers={"X-Title": "Vision Model Evaluator - Test"},
    )

def readable_time(sec: float) -> str:
    if sec < 1: return f"{sec*1000:.0f} –º—Å"
    if sec < 60: return f"{sec:.1f} —Å"
    m = int(sec // 60); s = int(sec % 60)
    return f"{m}–º {s}—Å"

def create_html_for_detailed_qa_pair(index: int, question: str, gen_answer: str, true_answer: str, time_elapsed: float) -> str:
    """
    creates well formatted colored html block for detailed Q&A pair
    :param index:
    :param question:
    :param gen_answer:
    :param true_answer:
    :param time_elapsed:
    :return:
    """
    return f"""
    <div style="border: 1px solid #ddd; border-radius: 8px; padding: 16px; margin-bottom: 16px;">
        <h4 style="margin-top: 0;">–í–æ–ø—Ä–æ—Å {index}</h4>
        <p><b>–í–æ–ø—Ä–æ—Å:</b> {question}</p>
        <p><b>–û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏:</b></p>
        <div style="background-color: #f9f9f9; padding: 12px; border-radius: 4px; white-space: pre-wrap;">{gen_answer}</div>
        <p><b>–í–µ—Ä–Ω—ã–π –æ—Ç–≤–µ—Ç:</b></p>
        <div style="background-color: #e8f5e9; padding: 12px; border-radius: 4px; white-space: pre-wrap;">{true_answer}</div>
        <p style="font-size: 0.9em; color: #555;">–í—Ä–µ–º—è: {readable_time(time_elapsed)}</p>
    </div>
    """

# ===========================
# –°–∞–π–¥–±–∞—Ä: –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
# ===========================
with st.sidebar:
    st.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")

    # –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ, —á—Ç–æ –±—ã–ª–æ –Ω–∞ –æ—Å–Ω–æ–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ, –µ—Å–ª–∏ –µ—Å—Ç—å
    default_img_dir = st.session_state.get("image_folder_path", "images")
    image_folder_path = st.text_input("–ü–∞–ø–∫–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏", value=default_img_dir)
    st.session_state.image_folder_path = image_folder_path  # —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ–º –≤ —Å–µ—Å—Å–∏—é

    st.divider()
    st.caption("–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ OpenRouter")
    openrouter_key = st.text_input(
        "API-–∫–ª—é—á OpenRouter",
        type="password",
        value=os.getenv("OPENROUTER_API_KEY", ""),
        help="–ö–ª—é—á –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –≤ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏."
    )

    st.markdown("–ú–æ–¥–µ–ª—å")
    model_name = st.text_input(
        "–ò–º—è –º–æ–¥–µ–ª–∏",
        value="openai/gpt-4o-mini",
        help="–ù–∞–ø—Ä–∏–º–µ—Ä: openai/gpt-4o, openai/gpt-4o-mini"
    )
    temperature = st.slider("–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞", 0.0, 1.0, 0.0, 0.05)
    max_tokens = st.slider("Max tokens", 512, 8192, 2048, 128)

# ===========================
# –î–∞–Ω–Ω—ã–µ
# ===========================
try:
    df = load_df_from_state_or_file()
    validate_df(df)
except Exception as e:
    st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞: {e}")
    st.stop()

if df.empty:
    st.warning("–î–∞—Ç–∞—Å–µ—Ç –ø—É—Å—Ç. –ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV –Ω–∞ –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ –∏–ª–∏ –ø–æ–ª–æ–∂–∏—Ç–µ —Ñ–∞–π–ª data.csv.")
    st.stop()

# ===========================
# –í—ã–±–æ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –≤–æ–ø—Ä–æ—Å–æ–≤
# ===========================
unique_images = sorted(df["image_name"].astype(str).unique().tolist())
if not unique_images:
    st.warning("–í –¥–∞—Ç–∞—Å–µ—Ç–µ –Ω–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.")
    st.stop()

col_top_left, col_top_right = st.columns([1, 1])
with col_top_left:
    selected_image = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞", options=unique_images, index=0)

rows_for_image = df[df["image_name"].astype(str) == str(selected_image)].copy()
available_q = len(rows_for_image)

with col_top_right:
    st.metric("–î–æ—Å—Ç—É–ø–Ω–æ –≤–æ–ø—Ä–æ—Å–æ–≤ –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é", available_q)

if available_q == 0:
    st.warning("–î–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–µ—Ç –≤–æ–ø—Ä–æ—Å–æ–≤.")
    st.stop()

# –ö–æ–Ω—Ç—Ä–æ–ª—ã –≤—ã–±–æ—Ä–∞ 3‚Äì5 –≤–æ–ø—Ä–æ—Å–æ–≤ (–∞–¥–∞–ø—Ç–∏—Ä—É–µ–º—Å—è –ø–æ–¥ –¥–æ—Å—Ç—É–ø–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ)
min_q = 3 if available_q >= 3 else 1
max_q = min(5, available_q)
selection_col1, selection_col2, selection_col3 = st.columns([1, 1, 1])
with selection_col1:
    random_sample = st.toggle("–°–ª—É—á–∞–π–Ω—ã–π –≤—ã–±–æ—Ä –≤–æ–ø—Ä–æ—Å–æ–≤", value=True)
with selection_col2:
    num_questions = st.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–ø—Ä–æ—Å–æ–≤", min_value=min_q, max_value=max_q, value=max_q, step=1)
with selection_col3:
    seed = st.number_input("Seed", min_value=0, value=42, step=1)

# –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤
prev_left, prev_right = st.columns([1.1, 1.3])
with prev_left:
    img_path = Path(image_folder_path) / str(selected_image)
    if img_path.exists():
        try:
            st.image(Image.open(img_path), caption=str(selected_image))
        except Exception:
            st.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–æ–±—Ä–∞–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.")
    else:
        st.error(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {img_path}")

with prev_right:
    st.markdown("–ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –≤–æ–ø—Ä–æ—Å–æ–≤")
    if random_sample:
        preview_df = rows_for_image.sample(n=num_questions, random_state=seed)
    else:
        preview_df = rows_for_image.head(n=num_questions)
    # st.dataframe(preview_df[["question", "answer"]].reset_index(drop=True), use_container_width=True)
    html = ""
    for i, row in preview_df.iterrows():
        q = str(row["question"])
        a = str(row["answer"])
        # small font, answer in expander
        html += f"""
        <div style="margin-bottom: 12px;">
            <b>–í–æ–ø—Ä–æ—Å {i+1}:</b> {q}<br/>
            <details>
                <summary style="cursor: pointer; color: #0066cc;">–ü–æ–∫–∞–∑–∞—Ç—å –æ—Ç–≤–µ—Ç</summary>
                <div style="margin-top: 4px; font-size: 0.9em; color: #333;">{a}</div>
            </details>
        </div>
        """
    st.markdown(html, unsafe_allow_html=True)


st.divider()

# ===========================
# –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∞
# ===========================
run_col, info_col = st.columns([1, 2])
with run_col:
    run = st.button("üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç—å —Ç–µ—Å—Ç", use_container_width=True)
with info_col:
    st.caption("–ë—É–¥—É—Ç –ø—Ä–æ–≥–Ω–∞–Ω—ã –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã –ø–æ –æ–¥–Ω–æ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é. –†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∞ –º–æ–¥–µ–ª–∏.")

if run:
    if not openrouter_key:
        st.error("–£–∫–∞–∂–∏—Ç–µ API-–∫–ª—é—á OpenRouter.")
        st.stop()
    if not img_path.exists():
        st.error(f"–§–∞–π–ª –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω: {img_path}")
        st.stop()

    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞
    vision_llm = get_llm(openrouter_key, model_name, temperature=temperature, max_tokens=max_tokens)
    if random_sample:
        test_df = rows_for_image.sample(n=num_questions, random_state=seed)
    else:
        test_df = rows_for_image.head(n=num_questions)

    results = []
    progress = st.progress(0)
    status = st.empty()

    # –ö–æ–¥–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –æ–¥–∏–Ω —Ä–∞–∑
    try:
        encoded = encode_image(img_path)
        mime = image_mime(img_path)
        img_url = f"data:{mime};base64,{encoded}"
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
        st.stop()

    start_all = time.time()
    for i, (_, r) in enumerate(test_df.iterrows(), start=1):
        q = str(r["question"])
        true_a = str(r["answer"])

        status.info(f"[{i}/{num_questions}] –í–æ–ø—Ä–æ—Å: {q[:60]}{'...' if len(q)>60 else ''}")
        t0 = time.time()

        try:
            msg = HumanMessage(content=[
                {"type": "text", "text": q},
                {"type": "image_url", "image_url": {"url": img_url}}
            ])
            res = vision_llm.invoke([msg])
            gen_a = res.content if hasattr(res, "content") else str(res)
        except Exception as e:
            gen_a = f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}"

        elapsed = time.time() - t0

        results.append({
            "question": q,
            "generated_answer": gen_a,
            "true_answer": true_a,
            "time_elapsed_sec": elapsed
        })
        progress.progress(i / num_questions)

    total_time = time.time() - start_all
    status.success(f"–ì–æ—Ç–æ–≤–æ –∑–∞ {readable_time(total_time)}")
    progress.empty()

    # –¢–∞–±–ª–∏—á–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã")
    res_df = pd.DataFrame(results)
    # –ü–µ—Ä–µ—É–ø–æ—Ä—è–¥–æ—á–∏–º —Å—Ç–æ–ª–±—Ü—ã
    res_df = res_df[["question", "generated_answer", "true_answer", "time_elapsed_sec"]]
    st.dataframe(res_df, use_container_width=True)

    # –î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ –≤–æ–ø—Ä–æ—Å–∞–º
    with st.expander("–ü–æ–¥—Ä–æ–±–Ω–æ –ø–æ –∫–∞–∂–¥–æ–º—É –≤–æ–ø—Ä–æ—Å—É", expanded=False):
        for idx, row in res_df.iterrows():
            html = create_html_for_detailed_qa_pair(
                index=idx + 1,
                question=row["question"],
                gen_answer=row["generated_answer"],
                true_answer=row["true_answer"],
                time_elapsed=row["time_elapsed_sec"]
            )
            st.markdown(html, unsafe_allow_html=True)

    # –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    st.subheader("–°–∫–∞—á–∞—Ç—å")
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    safe_model = model_name.replace("/", "_")
    out_meta = {
        "type": "single_image_test",
        "image_name": str(selected_image),
        "model_name": model_name,
        "timestamp": timestamp,
        "total_items": len(results),
        "total_time_sec": total_time,
        "image_path": str(img_path)
    }
    out_payload = {"meta": out_meta, "results": results}

    json_bytes = json.dumps(out_payload, ensure_ascii=False, indent=2).encode("utf-8")
    csv_bytes = res_df.to_csv(index=False).encode("utf-8")

    cdl1, cdl2 = st.columns(2)
    with cdl1:
        st.download_button(
            "‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å JSON",
            data=json_bytes,
            file_name=f"test_{safe_model}_{timestamp}.json",
            mime="application/json",
            use_container_width=True
        )
    with cdl2:
        st.download_button(
            "‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å CSV",
            data=csv_bytes,
            file_name=f"test_{safe_model}_{timestamp}.csv",
            mime="text/csv",
            use_container_width=True
        )